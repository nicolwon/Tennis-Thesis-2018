demo()
q()
library(rio)
library(dplyr)
library(knitr)
library(ggplot2)
library(rio)
library(dplyr)
library(knitr)
library(ggplot2)
transformer <- import("wo_ni_93.csv", fread=FALSE)
wo_ni_93 <- read.csv("~/Downloads/mie237_a1_data/wo_ni_93.csv")
View(wo_ni_93)
assign1 <- read.csv("~/Downloads/mie237_a1_data/wo_ni_93.csv")
View(assign1)
View(assign1)
wo_ni_93 <- read.csv("~/Downloads/mie237_a1_data/wo_ni_93.csv")
summary(lm(y ~ X1+X4+X2, data=y))
summary(lm(y ~ X2+X1, data=y2))
summary(lm(y ~ X2+X1, data=y2))
summary(lm(y ~ X2+X9+X3, data=y2))
summary(lm(y ~ X2+X9+X3, data=y2))
library("rstan")
options(mc.cores = parallel::detectCores())
source('~/.active-rstudio-document', echo=TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
plot(fit, ci_level = 0.95, outer_level = 0.999)
source('~/.active-rstudio-document', echo=TRUE)
print(fit)
# EXAMPLE 2: Beta-Bernoulli Model
# In this example, we fit a simple linear regression model of the form y = beta * x + noise.
# We assume the noise to follow a normal distribution with mean 0 and standard deviation sigma, i.e., N(0, sigma).
# Accordingly, given beta, y ~ N(beta * x, sigma). (You can check this fact using the concepts from MIE236.)
# In this example, we fit a simple linear regression model of the form y = bernoulli(p) + noise
# We assume the noise to follow a normal distribution with mean 0 and standard deviation sigma, i.e., N(0, sigma).
# Accordingly, given beta, y ~ N(beta * x, sigma). (You can check this fact using the concepts from MIE236.)
# clear workspace and screen
rm(list=ls())
cat("\f")
# set working directory (you should change it appropriately)
base_dir = "/Users/nicolewongsoo/Documents/Fourth\ Year\ Uni/Thesis/workspace/Tutorial\ 2"
setwd(base_dir)
# load libraries and set rstan's parallel computing options
library("rstan")
library("ggplot2")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# set random seed
set.seed(1)
# true values of beta and sigma
# ex. 100 trials --> 70 are success (1), 30 are failures
#
p = 0.7
sigma = 0.2
# input data
n = 100
# generate simulated output data
x = rbinom(n, 1, p)
mean(x)
mean(x)
# plot the simulated data
plot(x, pch = 20)
# compile the model present in the stan file (this might take a minute or two)
# FYI: you can open the stan file in RStudio to see the underlying code
model_bayesian = stan_model(file = "ex2_beta11.stan")
# prepare data for stan
data_stan = list(n, x)
data_stan
# fit the model (we usually use 4 chains and 1000 iterations for technical reasons; remind me to give you some intuition)
fit_bayesian = sampling(model_bayesian, data = data_stan, chains = 4, iter = 1000)
# print the summary of the fit (remind me to walk over this when we chat next)
print(fit_bayesian, digits = 2, pars = c("p"))
# plot the posterior distribution of beta
plot(fit_bayesian, pars = c("p"), show_density = TRUE)
# posterior "samples" of p
fit_extract = extract(fit_bayesian, permuted = TRUE)
p_samples = fit_extract$p # when we chat, remind me to tell you why beta_samples is of length 2000
# mean and sd of beta_samples (compare this with the summary output we printed a few lines above)
mean(p_samples)
sd(p_samples)
69/(69+33)
# histogram of beta_samples (compare this with the posterior distribution of beta we plotted a few lines above)
hist(p_samples)
# compile the model present in the stan file (this might take a minute or two)
# FYI: you can open the stan file in RStudio to see the underlying code
model_bayesian = stan_model(file = "ex2_beta11.stan")
